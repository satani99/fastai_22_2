{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOWYJVHY9PHr0Pfw822IBlF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/satani99/fastai_22_2/blob/main/Learner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/fastai/course22p2.git\n",
        "%cd course22p2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGLSLAgKQvfx",
        "outputId": "c8525aee-7c02-43b9-c361-6b3ec7672a6b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'course22p2'...\n",
            "remote: Enumerating objects: 1176, done.\u001b[K\n",
            "remote: Counting objects: 100% (1176/1176), done.\u001b[K\n",
            "remote: Compressing objects: 100% (480/480), done.\u001b[K\n",
            "remote: Total 1176 (delta 712), reused 1117 (delta 694), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1176/1176), 99.81 MiB | 24.81 MiB/s, done.\n",
            "Resolving deltas: 100% (712/712), done.\n",
            "/content/course22p2/course22p2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9j08nZKWRMQK",
        "outputId": "2c79cb20-7eee-4937-9fd5-dc91174e3785"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "i2ga9nUfQLr2"
      },
      "outputs": [],
      "source": [
        "import math, torch, matplotlib.pyplot as plt\n",
        "import fastcore.all as fc\n",
        "from collections.abc import Mapping\n",
        "from operator import attrgetter\n",
        "from functools import partial\n",
        "from copy import copy\n",
        "\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from miniai.conv import *\n",
        "\n",
        "from fastprogress import progress_bar, master_bar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import torchvision.transforms.functional as TF\n",
        "from contextlib import contextmanager\n",
        "from torch import nn, tensor\n",
        "from datasets import load_dataset, load_dataset_builder\n",
        "from miniai.conv import *\n",
        "from miniai.datasets import *\n",
        "import logging\n",
        "from fastcore.test import test_close"
      ],
      "metadata": {
        "id": "e3qxAN3IRH8x"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
        "torch.manual_seed(42)\n",
        "mpl.rcParams['image.cmap'] = 'gray'"
      ],
      "metadata": {
        "id": "P0Ih1N17Robv"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.disable(logging.WARNING)"
      ],
      "metadata": {
        "id": "0it0RN_dR3Nm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = 'image', 'label'\n",
        "name = 'fashion_mnist'\n",
        "dsd = load_dataset(name)"
      ],
      "metadata": {
        "id": "LbjnrpyRR9cL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@inplace\n",
        "def transformi(b): b[x] = [torch.flatten(TF.to_tensor(o)) for o in b[x]]"
      ],
      "metadata": {
        "id": "xfY_PjCoSIzd"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bs = 1024\n",
        "tds = dsd.with_transform(transformi)"
      ],
      "metadata": {
        "id": "BTBAmwW8Sl55"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dls = DataLoaders.from_dd(tds, bs, num_workers=4)\n",
        "dt = dls.train\n",
        "xb, yb = next(iter(dt))\n",
        "xb.shape, yb[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4RxIH2oSqnH",
        "outputId": "ec3aaac2-1c94-4dba-f246-7958f910d04d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1024, 784]), tensor([5, 7, 4, 7, 3, 8, 9, 5, 3, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Learner:\n",
        "  def __init__(self, model, dls, loss_func, lr, opt_func=optim.SGD): fc.store_attr()\n",
        "\n",
        "  def one_batch(self):\n",
        "    self.xb, self.yb = to_device(self.batch)\n",
        "    self.preds = self.model(self.xb)\n",
        "    self.loss = self.loss_func(self.preds, self.yb)\n",
        "    if self.model.training:\n",
        "      self.loss.backward()\n",
        "      self.opt.step()\n",
        "      self.opt.zero_grad()\n",
        "    with torch.no_grad(): self.calc_stats()\n",
        "\n",
        "  def calc_stats(self):\n",
        "    acc = (self.preds.argmax(dim=1)==self.yb).float().sum()\n",
        "    self.accs.append(acc)\n",
        "    n = len(self.xb)\n",
        "    self.losses.append(self.loss*n)\n",
        "    self.ns.append(n)\n",
        "\n",
        "  def one_epoch(self, train):\n",
        "    self.model.training = train\n",
        "    dl = self.dls.train if train else self.dls.valid\n",
        "    for self.num, self.batch in enumerate(dl): self.one_batch()\n",
        "    n = sum(self.ns)\n",
        "    print(self.epoch, self.model.training, sum(self.losses).item()/n, sum(self.accs).item()/n)\n",
        "\n",
        "  def fit(self, n_epochs):\n",
        "    self.accs, self.losses, self.ns = [], [], []\n",
        "    self.model.to(def_device)\n",
        "    self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
        "    self.n_epochs = n_epochs\n",
        "    for self.epoch in range(n_epochs):\n",
        "      self.one_epoch(True)\n",
        "      with torch.no_grad(): self.one_epoch(False)\n"
      ],
      "metadata": {
        "id": "FyzXxfUmS_P0"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m, nh = 28*28, 50\n",
        "model = nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
      ],
      "metadata": {
        "id": "G2aa6J7Uq7Wy"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(model, dls, F.cross_entropy, lr=0.2)\n",
        "learn.fit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj36_arDraQu",
        "outputId": "d4fbfc43-9dd8-46eb-c4f9-f44a3b0040f6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 True 1.1871040364583334 0.5921166666666666\n",
            "0 False 1.1323120535714286 0.6058714285714286\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CancelFitException(Exception): pass\n",
        "class CancelBatchException(Exception): pass\n",
        "class CancelEpochException(Exception): pass"
      ],
      "metadata": {
        "id": "OzzHIMvbrhWx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Callback(): order = 0"
      ],
      "metadata": {
        "id": "rVQQPVnXr6ZR"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_cbs(cbs, method_nm, learn=None):\n",
        "  for cb in sorted(cbs, key=attrgetter('order')):\n",
        "    method = getattr(cb, method_nm, None)\n",
        "    if method is not None: method(learn)"
      ],
      "metadata": {
        "id": "-pvF1An3r9YL"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CompletionCB(Callback):\n",
        "  def before_fit(self, learn): self.count = 0\n",
        "  def after_batch(self, learn): self.count += 1\n",
        "  def after_fit(self, learn): print(f'Completed {self.count} batches')"
      ],
      "metadata": {
        "id": "CZatNK7JsSIk"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cbs = [CompletionCB()]\n",
        "run_cbs(cbs, 'before_fit')\n",
        "run_cbs(cbs, 'after_batch')\n",
        "run_cbs(cbs, 'after_fit')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7U1DjDus8DF",
        "outputId": "796a591f-c4d0-4d03-c43e-013ff7fdae7e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 1 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Learner():\n",
        "  def __init__(self, model, dls, loss_func, lr, cbs, opt_func=optim.SGD): fc.store_attr()\n",
        "\n",
        "  def one_batch(self):\n",
        "    self.preds = self.model(self.batch[0])\n",
        "    self.loss = self.loss_func(self.preds, self.batch[1])\n",
        "    if self.model.training:\n",
        "      self.loss.backward()\n",
        "      self.opt.step()\n",
        "      self.opt.zero_grad()\n",
        "\n",
        "  def one_epoch(self, train):\n",
        "    self.model.train(train)\n",
        "    self.dl = self.dls.train if train else self.dls.valid\n",
        "    try:\n",
        "      self.callback('before_epoch')\n",
        "      for self.iter, self.batch in enumerate(self.dl):\n",
        "        try:\n",
        "          self.callback('before_batch')\n",
        "          self.one_batch()\n",
        "          self.callback('after_batch')\n",
        "        except CancelBatchException: pass\n",
        "      self.callback('after_epoch')\n",
        "    except CancelEpochException: pass\n",
        "\n",
        "  def fit(self, n_epochs):\n",
        "    self.n_epochs = n_epochs\n",
        "    self.epochs = range(n_epochs)\n",
        "    self.opt = self.opt_func(self.model.parameters(), self.lr)\n",
        "    try:\n",
        "      self.callback('before_fit')\n",
        "      for self.epoch in self.epochs:\n",
        "        self.one_epoch(True)\n",
        "        self.one_epoch(False)\n",
        "      self.callback('after_fit')\n",
        "    except CancelFitException: pass\n",
        "\n",
        "  def callback(self, method_nm): run_cbs(self.cbs, method_nm, self)"
      ],
      "metadata": {
        "id": "cTdzmh56tXyo"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "m, nh = 28*28, 50\n",
        "def get_model(): return nn.Sequential(nn.Linear(m, nh), nn.ReLU(), nn.Linear(nh, 10))"
      ],
      "metadata": {
        "id": "Kh8VPH-wwdNN"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = get_model()\n",
        "learn = Learner(model, dls, F.cross_entropy, lr=0.2, cbs=[CompletionCB()])\n",
        "learn.fit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYlcm1gJw5QK",
        "outputId": "09ac2565-43a2-4f4b-d2c4-8a776d674618"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 64 batches\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SingleBatchCB(Callback):\n",
        "  order = 1\n",
        "  def after_batch(self, learn): raise CancelFitException()"
      ],
      "metadata": {
        "id": "NbkvI0wUxEdo"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(get_model(), dls, F.cross_entropy, lr=0.2, cbs=[CompletionCB(), SingleBatchCB()])\n",
        "learn.fit(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b8aYDu8yun8",
        "outputId": "f9631beb-9ca0-4fa8-d7c0-8cbca64ca27e"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Metric:\n",
        "  def __init__(self): self.reset()\n",
        "  def reset(self): self.vals, self.ns = [], []\n",
        "  def add(self, inp, targ=None, n=1):\n",
        "    self.last = self.calc(inp, targ)\n",
        "    self.vals.append(self.last)\n",
        "    self.ns.append(n)\n",
        "  @property\n",
        "  def value(self):\n",
        "    ns = tensor(self.ns)\n",
        "    return (tensor(self.vals)*ns).sum()/ns.sum()\n",
        "  def calc(self, inps, targs): return inps"
      ],
      "metadata": {
        "id": "H0ihig980XMX"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Accuracy(Metric):\n",
        "  def calc(self, inps, targs): return (inps==targs).float().mean()"
      ],
      "metadata": {
        "id": "nh_gQdUP3aD-"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = Accuracy()\n",
        "acc.add(tensor([0, 1, 2, 0, 1, 2]), tensor([0, 1, 1, 2, 1, 0]))\n",
        "acc.add(tensor([1, 1, 2, 0, 1]), tensor([0, 1, 1, 2, 1]))\n",
        "acc.value"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wP06mksP336u",
        "outputId": "a5c15bb2-9590-49ef-c1da-4ab6c342c69c"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.45)"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = Metric()\n",
        "loss.add(0.6, n=32)\n",
        "loss.add(0.9, n=2)\n",
        "loss.value, round((0.6*32 + 0.9*2)/(32+2), 2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8G6nALPK8gf",
        "outputId": "44a6aed1-23f4-4479-fc4d-701f7adf77b9"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.62), 0.62)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torcheval"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWzMH-EPLauh",
        "outputId": "2cd6b9ba-eca1-46f0-d1c6-c011ace3acb0"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torcheval\n",
            "  Downloading torcheval-0.0.7-py3-none-any.whl (179 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.2/179.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torcheval) (4.7.1)\n",
            "Installing collected packages: torcheval\n",
            "Successfully installed torcheval-0.0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torcheval.metrics import MulticlassAccuracy, Mean"
      ],
      "metadata": {
        "id": "A4CIqu2ULkz_"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = MulticlassAccuracy()\n",
        "metric.update(tensor([0, 2, 1, 3]), tensor([0, 1, 2, 3]))\n",
        "metric.compute()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RUv7pmVLtrJ",
        "outputId": "6513c45e-8ddd-41f7-ea7a-c99e0239e6e5"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.50)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_OowyGsIL93E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}